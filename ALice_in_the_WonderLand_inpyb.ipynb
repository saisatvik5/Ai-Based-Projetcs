{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ALice in the WonderLand.inpyb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/saisatvik5/Playing-With-Ai-ML/blob/main/ALice_in_the_WonderLand_inpyb.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JrSYxmTHeezH"
      },
      "source": [
        "# LSTM Network \n",
        "\n",
        "Here I have tried to generate a text using a small LSTM Network. I have downloaded the given ASCII file and converted and stored in text format.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s5uQjIjQ-CYH"
      },
      "source": [
        "\n",
        "import numpy\n",
        "import sys\n",
        "import tensorflow as tf\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import LSTM, GRU\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.utils import np_utils"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nhfx5D7z-VBX",
        "outputId": "33ad8687-dcac-46e2-d3b1-cbae198d00ef"
      },
      "source": [
        "path_to_file = tf.keras.utils.get_file('Alice in the Wonder Land.txt', 'https://www.gutenberg.org/files/11/11-0.txt')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.gutenberg.org/files/11/11-0.txt\n",
            "180224/174313 [===============================] - 0s 1us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kZXdqm2cfRhk"
      },
      "source": [
        "### Here i have summerized the text. We have many characters which have to be removed to attain more clear vocabulary and Characters."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tLHI4nna-VFS",
        "outputId": "27d91993-c014-4fbc-e900-da32403d5b61"
      },
      "source": [
        "# Read, then decode for py2 compat.\n",
        "raw_text = open(path_to_file, 'rb').read().decode(encoding='utf-8')\n",
        "# length of text is the number of characters in it\n",
        "print(f'Length of text: {len(raw_text)} characters')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Length of text: 167808 characters\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tzwTvK-tgAQL"
      },
      "source": [
        "Now here i have printed the first 10,000 words of the raw_text. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3NEByh5q-VIF",
        "outputId": "6c013167-234e-4ce8-bf15-b10aa6a29e1a"
      },
      "source": [
        "print(raw_text[:10000])"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "﻿The Project Gutenberg eBook of Alice’s Adventures in Wonderland, by Lewis Carroll\r\n",
            "\r\n",
            "This eBook is for the use of anyone anywhere in the United States and\r\n",
            "most other parts of the world at no cost and with almost no restrictions\r\n",
            "whatsoever. You may copy it, give it away or re-use it under the terms\r\n",
            "of the Project Gutenberg License included with this eBook or online at\r\n",
            "www.gutenberg.org. If you are not located in the United States, you\r\n",
            "will have to check the laws of the country where you are located before\r\n",
            "using this eBook.\r\n",
            "\r\n",
            "Title: Alice’s Adventures in Wonderland\r\n",
            "\r\n",
            "Author: Lewis Carroll\r\n",
            "\r\n",
            "Release Date: January, 1991 [eBook #11]\r\n",
            "[Most recently updated: October 12, 2020]\r\n",
            "\r\n",
            "Language: English\r\n",
            "\r\n",
            "Character set encoding: UTF-8\r\n",
            "\r\n",
            "Produced by: Arthur DiBianca and David Widger\r\n",
            "\r\n",
            "*** START OF THE PROJECT GUTENBERG EBOOK ALICE’S ADVENTURES IN WONDERLAND ***\r\n",
            "\r\n",
            "[Illustration]\r\n",
            "\r\n",
            "\r\n",
            "\r\n",
            "\r\n",
            "Alice’s Adventures in Wonderland\r\n",
            "\r\n",
            "by Lewis Carroll\r\n",
            "\r\n",
            "THE MILLENNIUM FULCRUM EDITION 3.0\r\n",
            "\r\n",
            "Contents\r\n",
            "\r\n",
            " CHAPTER I.     Down the Rabbit-Hole\r\n",
            " CHAPTER II.    The Pool of Tears\r\n",
            " CHAPTER III.   A Caucus-Race and a Long Tale\r\n",
            " CHAPTER IV.    The Rabbit Sends in a Little Bill\r\n",
            " CHAPTER V.     Advice from a Caterpillar\r\n",
            " CHAPTER VI.    Pig and Pepper\r\n",
            " CHAPTER VII.   A Mad Tea-Party\r\n",
            " CHAPTER VIII.  The Queen’s Croquet-Ground\r\n",
            " CHAPTER IX.    The Mock Turtle’s Story\r\n",
            " CHAPTER X.     The Lobster Quadrille\r\n",
            " CHAPTER XI.    Who Stole the Tarts?\r\n",
            " CHAPTER XII.   Alice’s Evidence\r\n",
            "\r\n",
            "\r\n",
            "\r\n",
            "\r\n",
            "CHAPTER I.\r\n",
            "Down the Rabbit-Hole\r\n",
            "\r\n",
            "\r\n",
            "Alice was beginning to get very tired of sitting by her sister on the\r\n",
            "bank, and of having nothing to do: once or twice she had peeped into\r\n",
            "the book her sister was reading, but it had no pictures or\r\n",
            "conversations in it, “and what is the use of a book,” thought Alice\r\n",
            "“without pictures or conversations?”\r\n",
            "\r\n",
            "So she was considering in her own mind (as well as she could, for the\r\n",
            "hot day made her feel very sleepy and stupid), whether the pleasure of\r\n",
            "making a daisy-chain would be worth the trouble of getting up and\r\n",
            "picking the daisies, when suddenly a White Rabbit with pink eyes ran\r\n",
            "close by her.\r\n",
            "\r\n",
            "There was nothing so _very_ remarkable in that; nor did Alice think it\r\n",
            "so _very_ much out of the way to hear the Rabbit say to itself, “Oh\r\n",
            "dear! Oh dear! I shall be late!” (when she thought it over afterwards,\r\n",
            "it occurred to her that she ought to have wondered at this, but at the\r\n",
            "time it all seemed quite natural); but when the Rabbit actually _took a\r\n",
            "watch out of its waistcoat-pocket_, and looked at it, and then hurried\r\n",
            "on, Alice started to her feet, for it flashed across her mind that she\r\n",
            "had never before seen a rabbit with either a waistcoat-pocket, or a\r\n",
            "watch to take out of it, and burning with curiosity, she ran across the\r\n",
            "field after it, and fortunately was just in time to see it pop down a\r\n",
            "large rabbit-hole under the hedge.\r\n",
            "\r\n",
            "In another moment down went Alice after it, never once considering how\r\n",
            "in the world she was to get out again.\r\n",
            "\r\n",
            "The rabbit-hole went straight on like a tunnel for some way, and then\r\n",
            "dipped suddenly down, so suddenly that Alice had not a moment to think\r\n",
            "about stopping herself before she found herself falling down a very\r\n",
            "deep well.\r\n",
            "\r\n",
            "Either the well was very deep, or she fell very slowly, for she had\r\n",
            "plenty of time as she went down to look about her and to wonder what\r\n",
            "was going to happen next. First, she tried to look down and make out\r\n",
            "what she was coming to, but it was too dark to see anything; then she\r\n",
            "looked at the sides of the well, and noticed that they were filled with\r\n",
            "cupboards and book-shelves; here and there she saw maps and pictures\r\n",
            "hung upon pegs. She took down a jar from one of the shelves as she\r\n",
            "passed; it was labelled “ORANGE MARMALADE”, but to her great\r\n",
            "disappointment it was empty: she did not like to drop the jar for fear\r\n",
            "of killing somebody underneath, so managed to put it into one of the\r\n",
            "cupboards as she fell past it.\r\n",
            "\r\n",
            "“Well!” thought Alice to herself, “after such a fall as this, I shall\r\n",
            "think nothing of tumbling down stairs! How brave they’ll all think me\r\n",
            "at home! Why, I wouldn’t say anything about it, even if I fell off the\r\n",
            "top of the house!” (Which was very likely true.)\r\n",
            "\r\n",
            "Down, down, down. Would the fall _never_ come to an end? “I wonder how\r\n",
            "many miles I’ve fallen by this time?” she said aloud. “I must be\r\n",
            "getting somewhere near the centre of the earth. Let me see: that would\r\n",
            "be four thousand miles down, I think—” (for, you see, Alice had learnt\r\n",
            "several things of this sort in her lessons in the schoolroom, and\r\n",
            "though this was not a _very_ good opportunity for showing off her\r\n",
            "knowledge, as there was no one to listen to her, still it was good\r\n",
            "practice to say it over) “—yes, that’s about the right distance—but\r\n",
            "then I wonder what Latitude or Longitude I’ve got to?” (Alice had no\r\n",
            "idea what Latitude was, or Longitude either, but thought they were nice\r\n",
            "grand words to say.)\r\n",
            "\r\n",
            "Presently she began again. “I wonder if I shall fall right _through_\r\n",
            "the earth! How funny it’ll seem to come out among the people that walk\r\n",
            "with their heads downward! The Antipathies, I think—” (she was rather\r\n",
            "glad there _was_ no one listening, this time, as it didn’t sound at all\r\n",
            "the right word) “—but I shall have to ask them what the name of the\r\n",
            "country is, you know. Please, Ma’am, is this New Zealand or Australia?”\r\n",
            "(and she tried to curtsey as she spoke—fancy _curtseying_ as you’re\r\n",
            "falling through the air! Do you think you could manage it?) “And what\r\n",
            "an ignorant little girl she’ll think me for asking! No, it’ll never do\r\n",
            "to ask: perhaps I shall see it written up somewhere.”\r\n",
            "\r\n",
            "Down, down, down. There was nothing else to do, so Alice soon began\r\n",
            "talking again. “Dinah’ll miss me very much to-night, I should think!”\r\n",
            "(Dinah was the cat.) “I hope they’ll remember her saucer of milk at\r\n",
            "tea-time. Dinah my dear! I wish you were down here with me! There are\r\n",
            "no mice in the air, I’m afraid, but you might catch a bat, and that’s\r\n",
            "very like a mouse, you know. But do cats eat bats, I wonder?” And here\r\n",
            "Alice began to get rather sleepy, and went on saying to herself, in a\r\n",
            "dreamy sort of way, “Do cats eat bats? Do cats eat bats?” and\r\n",
            "sometimes, “Do bats eat cats?” for, you see, as she couldn’t answer\r\n",
            "either question, it didn’t much matter which way she put it. She felt\r\n",
            "that she was dozing off, and had just begun to dream that she was\r\n",
            "walking hand in hand with Dinah, and saying to her very earnestly,\r\n",
            "“Now, Dinah, tell me the truth: did you ever eat a bat?” when suddenly,\r\n",
            "thump! thump! down she came upon a heap of sticks and dry leaves, and\r\n",
            "the fall was over.\r\n",
            "\r\n",
            "Alice was not a bit hurt, and she jumped up on to her feet in a moment:\r\n",
            "she looked up, but it was all dark overhead; before her was another\r\n",
            "long passage, and the White Rabbit was still in sight, hurrying down\r\n",
            "it. There was not a moment to be lost: away went Alice like the wind,\r\n",
            "and was just in time to hear it say, as it turned a corner, “Oh my ears\r\n",
            "and whiskers, how late it’s getting!” She was close behind it when she\r\n",
            "turned the corner, but the Rabbit was no longer to be seen: she found\r\n",
            "herself in a long, low hall, which was lit up by a row of lamps hanging\r\n",
            "from the roof.\r\n",
            "\r\n",
            "There were doors all round the hall, but they were all locked; and when\r\n",
            "Alice had been all the way down one side and up the other, trying every\r\n",
            "door, she walked sadly down the middle, wondering how she was ever to\r\n",
            "get out again.\r\n",
            "\r\n",
            "Suddenly she came upon a little three-legged table, all made of solid\r\n",
            "glass; there was nothing on it except a tiny golden key, and Alice’s\r\n",
            "first thought was that it might belong to one of the doors of the hall;\r\n",
            "but, alas! either the locks were too large, or the key was too small,\r\n",
            "but at any rate it would not open any of them. However, on the second\r\n",
            "time round, she came upon a low curtain she had not noticed before, and\r\n",
            "behind it was a little door about fifteen inches high: she tried the\r\n",
            "little golden key in the lock, and to her great delight it fitted!\r\n",
            "\r\n",
            "Alice opened the door and found that it led into a small passage, not\r\n",
            "much larger than a rat-hole: she knelt down and looked along the\r\n",
            "passage into the loveliest garden you ever saw. How she longed to get\r\n",
            "out of that dark hall, and wander about among those beds of bright\r\n",
            "flowers and those cool fountains, but she could not even get her head\r\n",
            "through the doorway; “and even if my head would go through,” thought\r\n",
            "poor Alice, “it would be of very little use without my shoulders. Oh,\r\n",
            "how I wish I could shut up like a telescope! I think I could, if I only\r\n",
            "knew how to begin.” For, you see, so many out-of-the-way things had\r\n",
            "happened lately, that Alice had begun to think that very few things\r\n",
            "indeed were really impossible.\r\n",
            "\r\n",
            "There seemed to be no use in waiting by the little door, so she went\r\n",
            "back to the table, half hoping she might find another key on it, or at\r\n",
            "any rate a book of rules for shutting people up like telescopes: this\r\n",
            "time she found a little bottle on it, (“which certainly was not here\r\n",
            "before,” said Alice,) and round the neck of the bottle was a paper\r\n",
            "label, with the words “DRINK ME,” beautifully printed on it in large\r\n",
            "letters.\r\n",
            "\r\n",
            "It was all very well to say “Drink me,” but the wise little Alice was\r\n",
            "not going to do _that_ in a hurry. “No, I’ll look first,” she said,\r\n",
            "“and see whether it’s marked ‘_poison_’ or not”; for she had read\r\n",
            "several nice little histories about children who had got burnt, and\r\n",
            "eaten up by wild beasts and other unpleasant things, all because they\r\n",
            "_would_ not remember the simple rules their friends had taught them:\r\n",
            "such as, that a red-hot poker will burn you if you hold it too long;\r\n",
            "and that if you cut your finger _very_ deeply with a knife, it usually\r\n",
            "bleeds; and she had never forgotten that, if you drink much from a\r\n",
            "bottle marked “poison,” it is almost certain to disagree with you,\r\n",
            "sooner or later.\r\n",
            "\r\n",
            "However, this bottle was _not_ marked “poison,” so Alice ventured to\r\n",
            "taste it, and find\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QACea60Ngh4U"
      },
      "source": [
        "It is important to convert characters to integers to make it easy for my LSTM model to understand and get trained. \n",
        "\n",
        "All the Ascii characters which are to be removed or can not be read by my LSTM model will be converted into integers for better understanding of these patterns. ANd these patterns are useed to train our model and can understnad the novel better."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NVmDEcfPMi0s"
      },
      "source": [
        "raw_text = raw_text.lower()"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MP5aUpNFhy_b"
      },
      "source": [
        "chars = sorted(list(set(raw_text)))\n",
        "char_to_int = dict((c, i) for i, c in enumerate(chars))\n",
        "int_to_char = dict((i, c) for i, c in enumerate(chars))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JV6itgH_MivX",
        "outputId": "2ac48ddd-7000-47e3-dfdd-106b8d4f3a54"
      },
      "source": [
        "n_chars = len(raw_text)\n",
        "n_vocab = len(chars)\n",
        "print(\"Total Characters: \", n_chars)\n",
        "print(\"Total Vocab: \", n_vocab)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total Characters:  167808\n",
            "Total Vocab:  65\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JbfiboKg-Vf8",
        "outputId": "5f32b57a-3df4-48f3-8631-f9fa929e3b6c"
      },
      "source": [
        "seq_length = 100\n",
        "dataX = []\n",
        "dataY = []\n",
        "for i in range(0, n_chars - seq_length, 1):\n",
        "\tseq_in = raw_text[i:i + seq_length]\n",
        "\tseq_out = raw_text[i + seq_length]\n",
        "\tdataX.append([char_to_int[char] for char in seq_in])\n",
        "\tdataY.append(char_to_int[seq_out])\n",
        "n_patterns = len(dataX)\n",
        "print(\"Total Patterns: \", n_patterns)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total Patterns:  167708\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JfunB3g1h_RO"
      },
      "source": [
        "X = numpy.reshape(dataX, (n_patterns, seq_length, 1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bGYZ1gqziB9D"
      },
      "source": [
        "X = X / float(n_vocab)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M4J2dNxtMsHu"
      },
      "source": [
        "y = np_utils.to_categorical(dataY)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fg90wVvAiDfW"
      },
      "source": [
        "### Defining LSTM Model\n",
        "\n",
        "Down, I have coded for my LSTM model which will be helping me to understand the patterns or analyize the text of the novel"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ua6NbW0E-VkI"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(LSTM(256, input_shape=(X.shape[1], X.shape[2])))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(y.shape[1], activation='softmax'))\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam')"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3pGzTMEb-Vnk"
      },
      "source": [
        "\n",
        "filepath=\"weights-improvement-{epoch:02d}-{loss:.4f}.hdf5\"\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
        "callbacks_list = [checkpoint]"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iatUZucpjIj_"
      },
      "source": [
        "## Fit the model\n",
        "\n",
        "I run my model and check the epoch, which shows me the loss and accuracy i have attained using my defined model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6KZs1h4W-VrE",
        "outputId": "6635f703-1a4b-4453-e17d-4511746dee0e"
      },
      "source": [
        "model.fit(X[:100000], y[:100000], epochs=10, batch_size=128, callbacks=callbacks_list)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "782/782 [==============================] - 11s 14ms/step - loss: 2.6355\n",
            "\n",
            "Epoch 00001: loss improved from 2.68790 to 2.63546, saving model to weights-improvement-01-2.6355.hdf5\n",
            "Epoch 2/10\n",
            "782/782 [==============================] - 11s 14ms/step - loss: 2.5964\n",
            "\n",
            "Epoch 00002: loss improved from 2.63546 to 2.59643, saving model to weights-improvement-02-2.5964.hdf5\n",
            "Epoch 3/10\n",
            "782/782 [==============================] - 11s 14ms/step - loss: 2.5636\n",
            "\n",
            "Epoch 00003: loss improved from 2.59643 to 2.56357, saving model to weights-improvement-03-2.5636.hdf5\n",
            "Epoch 4/10\n",
            "782/782 [==============================] - 11s 14ms/step - loss: 2.5328\n",
            "\n",
            "Epoch 00004: loss improved from 2.56357 to 2.53284, saving model to weights-improvement-04-2.5328.hdf5\n",
            "Epoch 5/10\n",
            "782/782 [==============================] - 11s 14ms/step - loss: 2.5033\n",
            "\n",
            "Epoch 00005: loss improved from 2.53284 to 2.50325, saving model to weights-improvement-05-2.5033.hdf5\n",
            "Epoch 6/10\n",
            "782/782 [==============================] - 11s 15ms/step - loss: 2.4700\n",
            "\n",
            "Epoch 00006: loss improved from 2.50325 to 2.46999, saving model to weights-improvement-06-2.4700.hdf5\n",
            "Epoch 7/10\n",
            "782/782 [==============================] - 12s 15ms/step - loss: 2.4413\n",
            "\n",
            "Epoch 00007: loss improved from 2.46999 to 2.44134, saving model to weights-improvement-07-2.4413.hdf5\n",
            "Epoch 8/10\n",
            "782/782 [==============================] - 11s 15ms/step - loss: 2.4132\n",
            "\n",
            "Epoch 00008: loss improved from 2.44134 to 2.41318, saving model to weights-improvement-08-2.4132.hdf5\n",
            "Epoch 9/10\n",
            "782/782 [==============================] - 11s 15ms/step - loss: 2.3844\n",
            "\n",
            "Epoch 00009: loss improved from 2.41318 to 2.38442, saving model to weights-improvement-09-2.3844.hdf5\n",
            "Epoch 10/10\n",
            "782/782 [==============================] - 11s 14ms/step - loss: 2.3576\n",
            "\n",
            "Epoch 00010: loss improved from 2.38442 to 2.35760, saving model to weights-improvement-10-2.3576.hdf5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f54b6d1cb90>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mdUY5TiL-VyR",
        "outputId": "3b3f2ccf-5c7f-4c6c-8fc8-983c9990ddbc"
      },
      "source": [
        "# pick a random seed\n",
        "start = numpy.random.randint(0, len(dataX)-1)\n",
        "pattern = dataX[start]\n",
        "print(\"Seed:\")\n",
        "print(\"\\\"\", ''.join([int_to_char[value] for value in pattern]), \"\\\"\")"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Seed:\n",
            "\" dest tea-party i ever was at in\r\n",
            "all my life!”\r\n",
            "\r\n",
            "just as she said this, she noticed that one of the \"\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aqB7cs7y-V2d",
        "outputId": "8aa404a3-9d83-489c-ec21-9842527345a7"
      },
      "source": [
        "# generate characters\n",
        "for i in range(1000):\n",
        "\tx = numpy.reshape(pattern, (1, len(pattern), 1))\n",
        "\tx = x / float(n_vocab)\n",
        "\tprediction = model.predict(x, verbose=0)\n",
        "\tindex = numpy.argmax(prediction)\n",
        "\tresult = int_to_char[index]\n",
        "\tseq_in = [int_to_char[value] for value in pattern]\n",
        "\tsys.stdout.write(result)\n",
        "\tpattern.append(index)\n",
        "\tpattern = pattern[1:len(pattern)]\n",
        "print(\"\\nDone.\")"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "and the was io toe was soe tas io the woel  the was soen the was oo the\n",
            "toee  and the wose to tee toee  the was soen the was ani the was oo the\n",
            "toeee to tee toe toee  and the was io toe toee  and the was ani the was\n",
            "toe toe toe to tee was an the cad  no toe tas io the woel  and the woeee\n",
            "noe the was io toe toee  and the was io toe toee  and the was ani the\n",
            "aad to tee was ani the was io toe toee  and the was io toe toee  and the\n",
            "aot she was io toe toe toe to tee woel  the was ani the was oo the \n",
            "aaree an the woel  the wose to tee toee  the was soen the was oo the\n",
            "toeee to tee toee  the was soen the wosed toe tas io the woee  the wos\n",
            "\n",
            "toe toe toe to toe toe toe to tee was an the cad                                                                                                                                                                                                                      \n",
            "Done.\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}